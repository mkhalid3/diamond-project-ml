{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ee4eULaWpyRd"
      },
      "source": [
        "Import Essential Liberaries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9jhNqTM2qSkR"
      },
      "outputs": [],
      "source": [
        "!pip install catboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HhZmXPdmqjgG"
      },
      "outputs": [],
      "source": [
        "!pip install xgboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E3JwdS4On6BH"
      },
      "outputs": [],
      "source": [
        "# Import Essential Liberaries\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "# Modelling\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor,AdaBoostRegressor\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.linear_model import LinearRegression, Ridge,Lasso\n",
        "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from catboost import CatBoostRegressor\n",
        "from xgboost import XGBRegressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DsQEkE7OqBK1"
      },
      "outputs": [],
      "source": [
        "#read the dataset\n",
        "df = pd.read_csv('notebook\\data\\diamonds.csv')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LFPdKAySqBMT"
      },
      "outputs": [],
      "source": [
        "#split dataset into dependent(X) and independent(Y) variables\n",
        "X = df.drop(labels=['price'],axis=1)\n",
        "Y = df[['price']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nPWrR9u3qBRB"
      },
      "outputs": [],
      "source": [
        "#Creating Numerical Pipeline and Categorical Pipeline\n",
        "# ordinal-encoding and scaling of columns\n",
        "\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import OrdinalEncoder,StandardScaler\n",
        "\n",
        "categorical_cols = X.select_dtypes(include='object').columns\n",
        "numerical_cols = X.select_dtypes(exclude='object').columns\n",
        "\n",
        "# Define attributes for each ordinal variable\n",
        "cut_categories = ['Fair', 'Good', 'Very Good','Premium','Ideal']\n",
        "color_categories = ['D', 'E', 'F', 'G', 'H', 'I', 'J']\n",
        "clarity_categories = ['I1','SI2','SI1','VS2','VS1','VVS2','VVS1','IF']\n",
        "\n",
        "\n",
        "\n",
        "# Numerical Pipeline\n",
        "num_pipeline = Pipeline(\n",
        "                steps = [\n",
        "                ('imputer',SimpleImputer(strategy='median')),\n",
        "                ('scaler',StandardScaler())\n",
        "                ]\n",
        "            )\n",
        "\n",
        "# Categorical Pipeline\n",
        "cat_pipeline = Pipeline(\n",
        "                steps=[\n",
        "                ('imputer',SimpleImputer(strategy='most_frequent')),\n",
        "                ('ordinal_encoder',OrdinalEncoder(categories=[cut_categories,color_categories,clarity_categories])),\n",
        "                ('scaler',StandardScaler())\n",
        "                ]\n",
        "            )\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "                [\n",
        "                ('num_pipeline',num_pipeline,numerical_cols),\n",
        "                ('cat_pipeline',cat_pipeline,categorical_cols)\n",
        "                ]\n",
        "            )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RvQJa1UPqBTW"
      },
      "outputs": [],
      "source": [
        "# split the dataset into train set and test set\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,Y,test_size=0.2,random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jtfIizNqqBWx"
      },
      "outputs": [],
      "source": [
        "#transform the data according to pipelines\n",
        "X_train = pd.DataFrame(preprocessor.fit_transform(X_train),columns=preprocessor.get_feature_names_out())\n",
        "X_test = pd.DataFrame(preprocessor.transform(X_test),columns=preprocessor.get_feature_names_out())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mj-mTjgwqBYm"
      },
      "outputs": [],
      "source": [
        "preprocessor.get_feature_names_out()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JjpV07mgqBb-"
      },
      "outputs": [],
      "source": [
        "X_train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wPsZR7a2qBdf"
      },
      "outputs": [],
      "source": [
        "X_test.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cIPZmiagqBiF"
      },
      "outputs": [],
      "source": [
        "#create a function to gives all evaluation metrics to measure performance of models\n",
        "def evaluate_model(true, predicted):\n",
        "    mae = mean_absolute_error(true, predicted)\n",
        "    mse = mean_squared_error(true, predicted)\n",
        "    rmse = np.sqrt(mean_squared_error(true, predicted))\n",
        "    r2_square = r2_score(true, predicted)\n",
        "    return mae, rmse, r2_square"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sL7KLEssqBkC"
      },
      "outputs": [],
      "source": [
        "#train multiple models and evalute accuracy using evaluate model function\n",
        "\n",
        "models = {\n",
        "    \"Linear Regression\": LinearRegression(),\n",
        "    \"Lasso\": Lasso(),\n",
        "    \"Ridge\": Ridge(),\n",
        "    \"K-Neighbors Regressor\": KNeighborsRegressor(),\n",
        "    \"Decision Tree\": DecisionTreeRegressor(),\n",
        "    \"Random Forest Regressor\": RandomForestRegressor(),\n",
        "    \"XGBRegressor\": XGBRegressor(),\n",
        "    \"CatBoosting Regressor\": CatBoostRegressor(verbose=False),\n",
        "    \"AdaBoost Regressor\": AdaBoostRegressor()\n",
        "}\n",
        "model_list = []\n",
        "r2_list =[]\n",
        "\n",
        "for i in range(len(list(models))):\n",
        "    model = list(models.values())[i]\n",
        "    model.fit(X_train, y_train.values.flatten()) # Train model\n",
        "\n",
        "    # Make predictions\n",
        "    y_train_pred = model.predict(X_train)\n",
        "    y_test_pred = model.predict(X_test)\n",
        "\n",
        "    # Evaluate Train and Test dataset\n",
        "    model_train_mae , model_train_rmse, model_train_r2 = evaluate_model(y_train, y_train_pred)\n",
        "\n",
        "    model_test_mae , model_test_rmse, model_test_r2 = evaluate_model(y_test, y_test_pred)\n",
        "\n",
        "\n",
        "    print(list(models.keys())[i])\n",
        "    model_list.append(list(models.keys())[i])\n",
        "\n",
        "    print('Model performance for Training set')\n",
        "    print(\"- Root Mean Squared Error: {:.4f}\".format(model_train_rmse))\n",
        "    print(\"- Mean Absolute Error: {:.4f}\".format(model_train_mae))\n",
        "    print(\"- R2 Score: {:.4f}\".format(model_train_r2))\n",
        "\n",
        "    print('----------------------------------')\n",
        "\n",
        "    print('Model performance for Test set')\n",
        "    print(\"- Root Mean Squared Error: {:.4f}\".format(model_test_rmse))\n",
        "    print(\"- Mean Absolute Error: {:.4f}\".format(model_test_mae))\n",
        "    print(\"- R2 Score: {:.4f}\".format(model_test_r2))\n",
        "    r2_list.append(model_test_r2)\n",
        "\n",
        "    print('='*35)\n",
        "    print('\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TXPSNnwWqBnm"
      },
      "outputs": [],
      "source": [
        "#results of all implemented models\n",
        "df_results = pd.DataFrame(list(zip(model_list, r2_list)), columns=['Model Name', 'R2_Score']).sort_values(by=[\"R2_Score\"],ascending=False)\n",
        "df_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YJRFeEdtyOFL"
      },
      "outputs": [],
      "source": [
        "#HyperParameter Tuning started for catboost\n",
        "# Initializing catboost\n",
        "cbr = CatBoostRegressor(verbose=False)\n",
        "\n",
        "# Creating the hyperparameter grid\n",
        "param_dist = {'depth'          : [4,5,6,7,8,9, 10],\n",
        "              'learning_rate' : [0.01,0.02,0.03,0.04],\n",
        "               'iterations'    : [300,400,500,600]}\n",
        "\n",
        "#RandomSearchCV object\n",
        "rscv = RandomizedSearchCV(cbr , param_dist, scoring='r2', cv =5, n_jobs=-1)\n",
        "\n",
        "# Fit the model\n",
        "rscv.fit(X_train, y_train.values.flatten())\n",
        "\n",
        "# Print the tuned parameters and score\n",
        "print(rscv.best_params_)\n",
        "print(rscv.best_score_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xEhusUrqyOGw"
      },
      "outputs": [],
      "source": [
        "#function to predict, evaluate and print results\n",
        "def print_evaluated_results(model,xtrain,ytrain,xtest,ytest):\n",
        "    ytrain_pred = model.predict(xtrain)\n",
        "    ytest_pred = model.predict(xtest)\n",
        "\n",
        "    # Evaluate Train and Test dataset\n",
        "    model_train_mae , model_train_rmse, model_train_r2 = evaluate_model(ytrain, ytrain_pred)\n",
        "    model_test_mae , model_test_rmse, model_test_r2 = evaluate_model(ytest, ytest_pred)\n",
        "\n",
        "    # Printing results\n",
        "    print('Model performance for Training set')\n",
        "    print(\"- Root Mean Squared Error: {:.4f}\".format(model_train_rmse))\n",
        "    print(\"- Mean Absolute Error: {:.4f}\".format(model_train_mae))\n",
        "    print(\"- R2 Score: {:.4f}\".format(model_train_r2))\n",
        "\n",
        "    print('----------------------------------')\n",
        "\n",
        "    print('Model performance for Test set')\n",
        "    print(\"- Root Mean Squared Error: {:.4f}\".format(model_test_rmse))\n",
        "    print(\"- Mean Absolute Error: {:.4f}\".format(model_test_mae))\n",
        "    print(\"- R2 Score: {:.4f}\".format(model_test_r2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AfD09deZyOK4"
      },
      "outputs": [],
      "source": [
        "# Selecting best model and Evaluate Train and Test dataset\n",
        "best_cbr = rscv.best_estimator_\n",
        "\n",
        "print_evaluated_results(best_cbr,X_train,y_train,X_test,y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hYso3rvdu9NS"
      },
      "outputs": [],
      "source": [
        "#Hyperparameter tuning of KNN started\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "# Initialize knn\n",
        "knn = KNeighborsRegressor()\n",
        "\n",
        "# parameters\n",
        "k_range = list(range(2, 31))\n",
        "param_grid = dict(n_neighbors=k_range)\n",
        "\n",
        "# Fit the gridsearchCV model\n",
        "grid = GridSearchCV(knn, param_grid, cv=5, scoring='r2',n_jobs=-1)\n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "# Print the tuned parameters and score\n",
        "print(grid.best_params_)\n",
        "print(grid.best_score_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sMU-RhyVu9jg"
      },
      "outputs": [],
      "source": [
        "# Selecting best model and Evaluate Train and Test dataset\n",
        "best_knn = grid.best_estimator_\n",
        "\n",
        "print_evaluated_results(best_knn,X_train,y_train,X_test,y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "25rVNV2su9xx"
      },
      "outputs": [],
      "source": [
        "#xgboost tuning started\n",
        "# Initializing xgboost\n",
        "xgb = XGBRegressor()\n",
        "\n",
        "# Parameters\n",
        "params = {\n",
        " 'learning_rate' : [0.05,0.10,0.15,0.20,0.25,0.30],\n",
        " 'max_depth' : [ 3, 4, 5, 6, 8, 10, 12, 15],\n",
        " 'min_child_weight' : [ 1, 3, 5, 7 ],\n",
        " 'gamma': [ 0.0, 0.1, 0.2 , 0.3, 0.4 ],\n",
        " 'colsample_bytree' : [ 0.3, 0.4, 0.5 , 0.7 ],\n",
        " 'n_estimators':[300,400,500,600]\n",
        "}\n",
        "\n",
        "rs_xgb=RandomizedSearchCV(xgb,param_distributions=params,scoring='r2',n_jobs=-1,cv=5)\n",
        "rs_xgb.fit(X_train, y_train.values.flatten())\n",
        "\n",
        "# Print the tuned parameters and score\n",
        "print(rs_xgb.best_params_)\n",
        "print(rs_xgb.best_score_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gZbwTjNku993"
      },
      "outputs": [],
      "source": [
        "# Selecting best model and Evaluate Train and Test dataset\n",
        "best_xgb = rs_xgb.best_estimator_\n",
        "\n",
        "print_evaluated_results(best_xgb,X_train,y_train,X_test,y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y8DybPh4u-GP"
      },
      "outputs": [],
      "source": [
        "#voting Regressor\n",
        "from sklearn.ensemble import VotingRegressor\n",
        "\n",
        "er = VotingRegressor([('cbr',best_cbr),('knn',best_knn),('xgb',XGBRegressor())], weights=[3,1,2])\n",
        "er.fit(X_train, y_train.values.flatten())\n",
        "\n",
        "print_evaluated_results(er,X_train,y_train,X_test,y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IORpkh2Su-Ml"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2DxTXuupu-SF"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
